{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "attack = pd.read_excel('dados_ataque.xlsx')\n",
    "#display(attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "defense = pd.read_excel('dados_defesa.xlsx')\n",
    "#display(defense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "athletes = pd.read_excel('dados_atletas.xlsx')\n",
    "#display(athletes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_excel('dados_resultado.xlsx')\n",
    "#display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "call = pd.read_excel('dados_convocatoria.xlsx')\n",
    "#display(call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_goals = pd.read_excel('dados_golosmarcados.xlsx')\n",
    "#display(scored_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conceded_goals = pd.read_excel('dados_golossofridos.xlsx')\n",
    "#display(conceded_goals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_transpose = results.T\n",
    "results_transpose.columns = results_transpose.iloc[0]\n",
    "results_transpose = results_transpose.iloc[1:]\n",
    "#results_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transpose dataframe\n",
    "attack_transpose = attack.T\n",
    "attack_transpose.columns = attack_transpose.iloc[0]\n",
    "attack_transpose = attack_transpose.iloc[1:]\n",
    "\n",
    "#replace 0 with nan values for calculation\n",
    "attack_transpose =attack_transpose.replace(0, np.NaN)\n",
    "\n",
    "#create columns overview\n",
    "attack_transpose['A6x5 Overview'] = attack_transpose['A6x5 marcados']/attack_transpose['A6x5 TOTAL']\n",
    "attack_transpose['Penalty Overview'] = attack_transpose['Penalty marcados']/attack_transpose['Penalty TOTAL']\n",
    "\n",
    "#replace nan values again\n",
    "attack_transpose =attack_transpose.replace(np.NaN, 0)\n",
    "\n",
    "#display\n",
    "#display(attack_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "defense_transpose = defense.T\n",
    "defense_transpose.columns = defense_transpose.iloc[0]\n",
    "defense_transpose = defense_transpose.iloc[1:]\n",
    "\n",
    "#replace 0 with nan values for calculation\n",
    "defense_transpose =defense_transpose.replace(0, np.NaN)\n",
    "\n",
    "#create columns overview\n",
    "defense_transpose['D5x6 Overview'] = defense_transpose['D5x6 sofridos']/defense_transpose['D5x6 TOTAL']\n",
    "defense_transpose['Penalty Overview'] = defense_transpose['Penalty marcados']/defense_transpose['Penalty TOTAL']\n",
    "\n",
    "#replace nan values again\n",
    "defense_transpose = defense_transpose.replace(np.NaN, 0)\n",
    "\n",
    "#display\n",
    "#display(defense_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_goals_transpose = scored_goals.T\n",
    "scored_goals_transpose.columns = scored_goals_transpose.iloc[0]\n",
    "scored_goals_transpose = scored_goals_transpose.iloc[1:]\n",
    "scored_goals_transpose['total'] = scored_goals_transpose.sum(axis=1)\n",
    "#scored_goals_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conceded_goals_transpose = conceded_goals.T\n",
    "conceded_goals_transpose.columns = conceded_goals_transpose.iloc[0]\n",
    "conceded_goals_transpose = conceded_goals_transpose.iloc[1:]\n",
    "conceded_goals_transpose['total'] = conceded_goals_transpose.sum(axis=1)\n",
    "#conceded_goals_transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CROSSING CALLS WITH HEIGHT\n",
    "height_call = call[[\"Jogo 1\", \"Jogo 2\",\"Jogo 3\",\"Jogo 4\",\"Jogo 5\",\"Jogo 6\",\"Jogo 7\",\"Jogo 8\",\"Jogo 9\",\"Jogo 10\",\"Jogo 11\",\"Jogo 12\",\"Jogo 13\",\"Jogo 14\",\"Jogo 15\",\"Jogo 16\",\"Jogo 17\",\"Jogo 18\",\"Jogo 19\",\"Jogo 20\",\"Jogo 21\",\"Jogo 22\",\"Jogo 23\",\"Jogo 24\",\"Jogo 25\",\"Jogo 26\",\"Jogo 27\",\"Jogo 28\",\"Jogo 29\",\"Jogo 30\",]].multiply(athletes[\"altura (cm)\"], axis=\"index\")\n",
    "\n",
    "#for better analysis\n",
    "height_call_T = height_call.T\n",
    "#display(height_call_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CROSSING CALLS WITH WEIGHT\n",
    "weight_call = call[[\"Jogo 1\", \"Jogo 2\",\"Jogo 3\",\"Jogo 4\",\"Jogo 5\",\"Jogo 6\",\"Jogo 7\",\"Jogo 8\",\"Jogo 9\",\"Jogo 10\",\"Jogo 11\",\"Jogo 12\",\"Jogo 13\",\"Jogo 14\",\"Jogo 15\",\"Jogo 16\",\"Jogo 17\",\"Jogo 18\",\"Jogo 19\",\"Jogo 20\",\"Jogo 21\",\"Jogo 22\",\"Jogo 23\",\"Jogo 24\",\"Jogo 25\",\"Jogo 26\",\"Jogo 27\",\"Jogo 28\",\"Jogo 29\",\"Jogo 30\",]].multiply(athletes[\"Peso (kg)\"], axis=\"index\")\n",
    "\n",
    "#for better analysis\n",
    "weight_call_T = weight_call.T\n",
    "#display(weight_call_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSSING CALLS WITH IMC\n",
    "imc_call = call[[\"Jogo 1\", \"Jogo 2\",\"Jogo 3\",\"Jogo 4\",\"Jogo 5\",\"Jogo 6\",\"Jogo 7\",\"Jogo 8\",\"Jogo 9\",\"Jogo 10\",\"Jogo 11\",\"Jogo 12\",\"Jogo 13\",\"Jogo 14\",\"Jogo 15\",\"Jogo 16\",\"Jogo 17\",\"Jogo 18\",\"Jogo 19\",\"Jogo 20\",\"Jogo 21\",\"Jogo 22\",\"Jogo 23\",\"Jogo 24\",\"Jogo 25\",\"Jogo 26\",\"Jogo 27\",\"Jogo 28\",\"Jogo 29\",\"Jogo 30\",]].multiply(athletes[\"IMC\"], axis=\"index\")\n",
    "\n",
    "#for better analysis\n",
    "imc_call_T = imc_call.T\n",
    "#display(imc_call_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA: Does Physical characteristics of a squad affect the performance in a game? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H1: Physical characteristics of a squad do not affect the result obtained in a game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.938965153878124, pvalue=0.34830011073042566)\n",
      "180.6590909090909\n",
      "181.48952380952383\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the results\n",
    "merge_height_result = pd.merge(height_call_T, results_transpose, left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_height_result = pd.melt(merge_height_result.reset_index(),id_vars=['index','Resultado'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_height_result = melt_height_result.loc[(melt_height_result['Resultado']=='Vitória') & (melt_height_result['value']>0)]\n",
    "lowperformance_height_result = melt_height_result.loc[((melt_height_result['Resultado']=='Derrota')|(melt_height_result['Resultado']=='Empate')) & (melt_height_result['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_height_result['value'], lowperformance_height_result['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_height_result['value'].mean())\n",
    "print(lowperformance_height_result['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.8352499886572817, pvalue=0.40406223479510617)\n",
      "70.70876623376637\n",
      "71.42190476190474\n"
     ]
    }
   ],
   "source": [
    "#merging the tables weight_call_t with the results\n",
    "merge_weight_result = pd.merge(weight_call_T, results_transpose, left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_weight_result = pd.melt(merge_weight_result.reset_index(),id_vars=['index','Resultado'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_weight_result = melt_weight_result.loc[(melt_weight_result['Resultado']=='Vitória') & (melt_weight_result['value']>0)]\n",
    "lowperformance_weight_result = melt_weight_result.loc[((melt_weight_result['Resultado']=='Derrota')|(melt_weight_result['Resultado']=='Empate')) & (melt_weight_result['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_weight_result['value'], lowperformance_weight_result['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_weight_result['value'].mean())\n",
    "print(lowperformance_weight_result['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.19700647696886264, pvalue=0.8439198540928536)\n",
      "21.658187674536425\n",
      "21.700633169278436\n"
     ]
    }
   ],
   "source": [
    "#merging the tables weight_call_t with the results\n",
    "merge_imc_result = pd.merge(imc_call_T, results_transpose, left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_imc_result = pd.melt(merge_imc_result.reset_index(),id_vars=['index','Resultado'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_imc_result = melt_imc_result.loc[(melt_imc_result['Resultado']=='Vitória') & (melt_imc_result['value']>0)]\n",
    "lowperformance_imc_result = melt_imc_result.loc[((melt_imc_result['Resultado']=='Derrota')|(melt_imc_result['Resultado']=='Empate')) & (melt_imc_result['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_imc_result['value'], lowperformance_imc_result['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_imc_result['value'].mean())\n",
    "print(lowperformance_imc_result['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We don't reject the null hypothesis because the mean of the high performance is different from the mean of the low performance. So the physical characteristics don't affect the results in a game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H2: Physical characteristics of a squad do not affect the scored goals in a game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.18203950259129048, pvalue=0.8556414744660243)\n",
      "180.6590909090909\n",
      "181.48952380952383\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_height_scored_goals = pd.merge(height_call_T, scored_goals_transpose['total'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_height_scored_goals = pd.melt(merge_height_scored_goals.reset_index(),id_vars=['index','total'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_height_scored_goals = melt_height_scored_goals.loc[(melt_height_scored_goals['total'] > 14) & (melt_height_scored_goals['value']>0)]\n",
    "lowperformance_height_scored_goals = melt_height_scored_goals.loc[(melt_height_scored_goals['total'] <= 14) & (melt_height_scored_goals['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_height_scored_goals['value'], lowperformance_height_scored_goals['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_height_result['value'].mean())\n",
    "print(lowperformance_height_result['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.06385489198107717, pvalue=0.9491168141832811)\n",
      "70.70876623376637\n",
      "71.42190476190474\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_weight_scored_goals = pd.merge(weight_call_T, scored_goals_transpose['total'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_weight_scored_goals = pd.melt(merge_weight_scored_goals.reset_index(),id_vars=['index','total'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_weight_scored_goals = melt_weight_scored_goals.loc[(melt_weight_scored_goals['total'] > 14) & (melt_weight_scored_goals['value']>0)]\n",
    "lowperformance_weight_scored_goals = melt_weight_scored_goals.loc[(melt_weight_scored_goals['total'] <= 14) & (melt_weight_scored_goals['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_weight_scored_goals['value'], lowperformance_weight_scored_goals['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_weight_result['value'].mean())\n",
    "print(lowperformance_weight_result['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.16962829411355548, pvalue=0.8653859285041343)\n",
      "21.658187674536425\n",
      "21.700633169278436\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_imc_scored_goals = pd.merge(imc_call_T, scored_goals_transpose['total'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_imc_scored_goals = pd.melt(merge_imc_scored_goals.reset_index(),id_vars=['index','total'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_imc_scored_goals = melt_imc_scored_goals.loc[(melt_imc_scored_goals['total'] > 14) & (melt_imc_scored_goals['value']>0)]\n",
    "lowperformance_imc_scored_goals = melt_imc_scored_goals.loc[(melt_imc_scored_goals['total'] <= 14) & (melt_imc_scored_goals['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_imc_scored_goals['value'], lowperformance_imc_scored_goals['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_imc_result['value'].mean())\n",
    "print(lowperformance_imc_result['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We reject the null hypothesis because the mean of the high performance is different from the mean of the low performance. So the physical characteristics affect the scored goals in a game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H3: Physical characteristics of a squad do not affect the conceded goals  in a game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.5724707122621906, pvalue=0.5673161327719864)\n",
      "180.6590909090909\n",
      "181.48952380952383\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_height_conceded_goals = pd.merge(height_call_T, conceded_goals_transpose['total'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_height_conceded_goals = pd.melt(merge_height_conceded_goals.reset_index(),id_vars=['index','total'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_height_conceded_goals = melt_height_conceded_goals.loc[(melt_height_conceded_goals['total'] > 8) & (melt_height_conceded_goals['value']>0)]\n",
    "lowperformance_height_conceded_goals = melt_height_conceded_goals.loc[(melt_height_conceded_goals['total'] <= 8) & (melt_height_conceded_goals['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_height_conceded_goals['value'], lowperformance_height_conceded_goals['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_height_result['value'].mean())\n",
    "print(lowperformance_height_result['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.8340866768676389, pvalue=0.40471664804407737)\n",
      "70.70876623376637\n",
      "71.42190476190474\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_weight_conceded_goals = pd.merge(weight_call_T, conceded_goals_transpose['total'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_weight_conceded_goals = pd.melt(merge_weight_conceded_goals.reset_index(),id_vars=['index','total'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_weight_conceded_goals = melt_weight_conceded_goals.loc[(melt_weight_conceded_goals['total'] > 8) & (melt_weight_conceded_goals['value']>0)]\n",
    "lowperformance_weight_conceded_goals = melt_weight_conceded_goals.loc[(melt_weight_conceded_goals['total'] <= 8) & (melt_weight_conceded_goals['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_weight_conceded_goals['value'], lowperformance_weight_conceded_goals['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_weight_result['value'].mean())\n",
    "print(lowperformance_weight_result['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.514999738175605, pvalue=0.6068300590199838)\n",
      "21.658187674536425\n",
      "21.700633169278436\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_imc_conceded_goals = pd.merge(imc_call_T, conceded_goals_transpose['total'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_imc_conceded_goals = pd.melt(merge_imc_conceded_goals.reset_index(),id_vars=['index','total'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_imc_conceded_goals = melt_imc_conceded_goals.loc[(melt_imc_conceded_goals['total'] > 8) & (melt_imc_conceded_goals['value']>0)]\n",
    "lowperformance_imc_conceded_goals = melt_imc_conceded_goals.loc[(melt_imc_conceded_goals['total'] <= 8) & (melt_imc_conceded_goals['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_imc_conceded_goals['value'], lowperformance_imc_conceded_goals['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_imc_result['value'].mean())\n",
    "print(lowperformance_imc_result['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We reject the null hypothesis because the mean of the high performance is different from the mean of the low performance. So the physical characteristics affect the conceded goals in a game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H4: Physical characteristics of a squad do not affect how goals scored in a game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.6623463610998104, pvalue=0.5081204975401972)\n",
      "181.16201117318437\n",
      "180.64700854700854\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_height_penalty = pd.merge(height_call_T, attack_transpose['Penalty Overview'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_height_penalty = pd.melt(merge_height_penalty.reset_index(),id_vars=['index','Penalty Overview'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_height_penalty = melt_height_penalty.loc[(melt_height_penalty['Penalty Overview'] == 1)  & (melt_height_penalty['value']>0)]\n",
    "lowperformance_height_penalty = melt_height_penalty.loc[(melt_height_penalty['Penalty Overview'] < 1)  & (melt_height_penalty['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_height_penalty['value'], lowperformance_height_penalty['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_height_penalty['value'].mean())\n",
    "print(lowperformance_height_penalty['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=1.083290637124145, pvalue=0.279314541734414)\n",
      "71.35027932960898\n",
      "70.53803418803426\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_weight_penalty = pd.merge(weight_call_T, attack_transpose['Penalty Overview'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_weight_penalty = pd.melt(merge_weight_penalty.reset_index(),id_vars=['index','Penalty Overview'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_weight_penalty = melt_weight_penalty.loc[(melt_weight_penalty['Penalty Overview'] == 1)  & (melt_weight_penalty['value']>0)]\n",
    "lowperformance_weight_penalty = melt_weight_penalty.loc[(melt_weight_penalty['Penalty Overview'] < 1)  & (melt_weight_penalty['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_weight_penalty['value'], lowperformance_weight_penalty['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_weight_penalty['value'].mean())\n",
    "print(lowperformance_weight_penalty['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.7395853294992705, pvalue=0.45997385493232834)\n",
      "21.748260510973385\n",
      "21.608331859261558\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_imc_penalty = pd.merge(imc_call_T, attack_transpose['Penalty Overview'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_imc_penalty = pd.melt(merge_imc_penalty.reset_index(),id_vars=['index','Penalty Overview'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_imc_penalty = melt_imc_penalty.loc[(melt_imc_penalty['Penalty Overview'] == 1)  & (melt_imc_penalty['value']>0)]\n",
    "lowperformance_imc_penalty = melt_imc_penalty.loc[(melt_imc_penalty['Penalty Overview'] < 1)  & (melt_imc_penalty['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_imc_penalty['value'], lowperformance_imc_penalty['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_imc_penalty['value'].mean())\n",
    "print(lowperformance_imc_penalty['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A6x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.7937738867819196, pvalue=0.42778511637653105)\n",
      "180.40873015873015\n",
      "181.07282229965156\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_height_a6x5 = pd.merge(height_call_T, attack_transpose['A6x5 Overview'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_height_a6x5 = pd.melt(merge_height_a6x5.reset_index(),id_vars=['index','A6x5 Overview'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_height_a6x5 = melt_height_a6x5.loc[(melt_height_a6x5['A6x5 Overview'] > 0.6) & (melt_height_a6x5['value']>0)]\n",
    "lowperformance_height_a6x5 = melt_height_a6x5.loc[(melt_height_a6x5['A6x5 Overview'] <= 0.6) & (melt_height_a6x5['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_height_a6x5['value'], lowperformance_height_a6x5['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_height_a6x5['value'].mean())\n",
    "print(lowperformance_height_a6x5['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-1.1870527138540274, pvalue=0.2358924694103628)\n",
      "70.22460317460317\n",
      "71.18222996515694\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_weight_a6x5 = pd.merge(weight_call_T, attack_transpose['A6x5 Overview'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_weight_a6x5 = pd.melt(merge_weight_a6x5.reset_index(),id_vars=['index','A6x5 Overview'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_weight_a6x5 = melt_weight_a6x5.loc[(melt_weight_a6x5['A6x5 Overview'] > 0.6) & (melt_weight_a6x5['value']>0)]\n",
    "lowperformance_weight_a6x5 = melt_weight_a6x5.loc[(melt_weight_a6x5['A6x5 Overview'] <= 0.6) & (melt_weight_a6x5['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_weight_a6x5['value'], lowperformance_weight_a6x5['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_weight_a6x5['value'].mean())\n",
    "print(lowperformance_weight_a6x5['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.7682042446900048, pvalue=0.4428070033073017)\n",
      "21.560283201576993\n",
      "21.71669896561934\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_imc_a6x5 = pd.merge(imc_call_T, attack_transpose['A6x5 Overview'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_imc_a6x5 = pd.melt(merge_imc_a6x5.reset_index(),id_vars=['index','A6x5 Overview'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_imc_a6x5 = melt_imc_a6x5.loc[(melt_imc_a6x5['A6x5 Overview'] > 0.6) & (melt_imc_a6x5['value']>0)]\n",
    "lowperformance_imc_a6x5 = melt_imc_a6x5.loc[(melt_imc_a6x5['A6x5 Overview'] <= 0.6) & (melt_imc_a6x5['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_imc_a6x5['value'], lowperformance_imc_a6x5['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_imc_a6x5['value'].mean())\n",
    "print(lowperformance_imc_a6x5['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A6x6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.292138436742351, pvalue=0.770328187537555)\n",
      "180.99462365591398\n",
      "180.768281938326\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_height_a6x6 = pd.merge(height_call_T, attack_transpose['A6x6'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_height_a6x6 = pd.melt(merge_height_a6x6.reset_index(),id_vars=['index','A6x6'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_height_a6x6 = melt_height_a6x6.loc[(melt_height_a6x6['A6x6'] > 7) & (melt_height_a6x6['value']>0)]\n",
    "lowperformance_height_a6x6 = melt_height_a6x6.loc[(melt_height_a6x6['A6x6'] <= 7) & (melt_height_a6x6['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_height_a6x6['value'], lowperformance_height_a6x6['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_height_a6x6['value'].mean())\n",
    "print(lowperformance_height_a6x6['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.9236567915305327, pvalue=0.3562069743796493)\n",
      "71.2693548387097\n",
      "70.57929515418509\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_weight_a6x6 = pd.merge(weight_call_T, attack_transpose['A6x6'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_weight_a6x6 = pd.melt(merge_weight_a6x6.reset_index(),id_vars=['index','A6x6'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_weight_a6x6 = melt_weight_a6x6.loc[(melt_weight_a6x6['A6x6'] > 7) & (melt_weight_a6x6['value']>0)]\n",
    "lowperformance_weight_a6x6 = melt_weight_a6x6.loc[(melt_weight_a6x6['A6x6'] <= 7) & (melt_weight_a6x6['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_weight_a6x6['value'], lowperformance_weight_a6x6['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_weight_a6x6['value'].mean())\n",
    "print(lowperformance_weight_a6x6['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.7917996472349788, pvalue=0.4289342452825954)\n",
      "21.750982390646428\n",
      "21.60178661617268\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_imc_a6x6 = pd.merge(imc_call_T, attack_transpose['A6x6'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_imc_a6x6 = pd.melt(merge_imc_a6x6.reset_index(),id_vars=['index','A6x6'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_imc_a6x6 = melt_imc_a6x6.loc[(melt_imc_a6x6['A6x6'] > 7) & (melt_imc_a6x6['value']>0)]\n",
    "lowperformance_imc_a6x6 = melt_imc_a6x6.loc[(melt_imc_a6x6['A6x6'] <= 7) & (melt_imc_a6x6['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_imc_a6x6['value'], lowperformance_imc_a6x6['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_imc_a6x6['value'].mean())\n",
    "print(lowperformance_imc_a6x6['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counter-attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.4394040097585094, pvalue=0.6605997561527641)\n",
      "180.66467065868264\n",
      "181.009756097561\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_height_ca = pd.merge(height_call_T, attack_transpose['Contra-ataque'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_height_ca = pd.melt(merge_height_ca.reset_index(),id_vars=['index','Contra-ataque'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_height_ca = melt_height_ca.loc[(melt_height_ca['Contra-ataque'] > 4) & (melt_height_ca['value']>0)]\n",
    "lowperformance_height_ca = melt_height_ca.loc[(melt_height_ca['Contra-ataque'] <= 4) & (melt_height_ca['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_height_ca['value'], lowperformance_height_ca['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_height_ca['value'].mean())\n",
    "print(lowperformance_height_ca['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.30423641973535204, pvalue=0.7611017562261366)\n",
      "70.75269461077846\n",
      "70.9833333333334\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_weight_ca = pd.merge(weight_call_T, attack_transpose['Contra-ataque'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_weight_ca = pd.melt(merge_weight_ca.reset_index(),id_vars=['index','Contra-ataque'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_weight_ca = melt_weight_ca.loc[(melt_weight_ca['Contra-ataque'] > 4) & (melt_weight_ca['value']>0)]\n",
    "lowperformance_weight_ca = melt_weight_ca.loc[(melt_weight_ca['Contra-ataque'] <= 4) & (melt_weight_ca['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_weight_ca['value'], lowperformance_weight_ca['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_weight_ca['value'].mean())\n",
    "print(lowperformance_weight_ca['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.021666868497326366, pvalue=0.9827242075402647)\n",
      "21.66651174508992\n",
      "21.670653760574908\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_imc_ca = pd.merge(imc_call_T, attack_transpose['Contra-ataque'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_imc_ca = pd.melt(merge_imc_ca.reset_index(),id_vars=['index','Contra-ataque'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_imc_ca = melt_imc_ca.loc[(melt_imc_ca['Contra-ataque'] > 4) & (melt_imc_ca['value']>0)]\n",
    "lowperformance_imc_ca = melt_imc_ca.loc[(melt_imc_ca['Contra-ataque'] <= 4) & (melt_imc_ca['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_imc_ca['value'], lowperformance_imc_ca['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_imc_ca['value'].mean())\n",
    "print(lowperformance_imc_ca['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We reject the null hypothesis because in all type of goals the high performance mean and low performance mean is different. So the physical characteristics affect the type of scored goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H5: Physical characteristics of a squad do not affect the type of goals conceded in a game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.2289341979002059, pvalue=0.8190339319145924)\n",
      "180.9440329218107\n",
      "180.76470588235293\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_height_penalty_d = pd.merge(height_call_T, defense_transpose['Penalty Overview'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_height_penalty_d = pd.melt(merge_height_penalty_d.reset_index(),id_vars=['index','Penalty Overview'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_height_penalty_d = melt_height_penalty_d.loc[(melt_height_penalty_d['Penalty Overview'] <= 0.5)  & (melt_height_penalty_d['value']>0)]\n",
    "lowperformance_height_penalty_d = melt_height_penalty_d.loc[(melt_height_penalty_d['Penalty Overview'] > 0.5)  & (melt_height_penalty_d['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_height_penalty_d['value'], lowperformance_height_penalty_d['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_height_penalty_d['value'].mean())\n",
    "print(lowperformance_height_penalty_d['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.332102650535627, pvalue=0.7399810475373106)\n",
      "70.99341563786015\n",
      "70.74235294117649\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_weight_penalty_d = pd.merge(weight_call_T, defense_transpose['Penalty Overview'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_weight_penalty_d = pd.melt(merge_weight_penalty_d.reset_index(),id_vars=['index','Penalty Overview'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_weight_penalty_d = melt_weight_penalty_d.loc[(melt_weight_penalty_d['Penalty Overview'] <= 0.5)  & (melt_weight_penalty_d['value']>0)]\n",
    "lowperformance_weight_penalty_d = melt_weight_penalty_d.loc[(melt_weight_penalty_d['Penalty Overview'] > 0.5)  & (melt_weight_penalty_d['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_weight_penalty_d['value'], lowperformance_weight_penalty_d['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_weight_penalty_d['value'].mean())\n",
    "print(lowperformance_weight_penalty_d['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.17583053976495353, pvalue=0.8605136740043647)\n",
      "21.68277609870739\n",
      "21.64925702673852\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_imc_penalty_d = pd.merge(imc_call_T, defense_transpose['Penalty Overview'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_imc_penalty_d = pd.melt(merge_imc_penalty_d.reset_index(),id_vars=['index','Penalty Overview'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_imc_penalty_d = melt_imc_penalty_d.loc[(melt_imc_penalty_d['Penalty Overview'] <= 0.5)  & (melt_imc_penalty_d['value']>0)]\n",
    "lowperformance_imc_penalty_d = melt_imc_penalty_d.loc[(melt_imc_penalty_d['Penalty Overview'] > 0.5)  & (melt_imc_penalty_d['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_imc_penalty_d['value'], lowperformance_imc_penalty_d['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_imc_penalty_d['value'].mean())\n",
    "print(lowperformance_imc_penalty_d['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D5x6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.10739327077623247, pvalue=0.9145293959432109)\n",
      "180.85365168539326\n",
      "180.97368421052633\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_height_d5x6 = pd.merge(height_call_T, defense_transpose['D5x6 Overview'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_height_d5x6 = pd.melt(merge_height_d5x6.reset_index(),id_vars=['index','D5x6 Overview'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_height_d5x6 = melt_height_d5x6.loc[(melt_height_d5x6['D5x6 Overview'] < 0.4)  & (melt_height_d5x6['value']>0)]\n",
    "lowperformance_height_d5x6 = melt_height_d5x6.loc[(melt_height_d5x6['D5x6 Overview'] >= 0.4)  & (melt_height_d5x6['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_height_d5x6['value'], lowperformance_height_d5x6['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_height_d5x6['value'].mean())\n",
    "print(lowperformance_height_d5x6['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.9696038944247835, pvalue=0.3328142114341869)\n",
      "71.03426966292136\n",
      "69.98947368421051\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_weight_d5x6 = pd.merge(weight_call_T, defense_transpose['D5x6 Overview'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_weight_d5x6 = pd.melt(merge_weight_d5x6.reset_index(),id_vars=['index','D5x6 Overview'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_weight_d5x6 = melt_weight_d5x6.loc[(melt_weight_d5x6['D5x6 Overview'] < 0.4)  & (melt_weight_d5x6['value']>0)]\n",
    "lowperformance_weight_d5x6 = melt_weight_d5x6.loc[(melt_weight_d5x6['D5x6 Overview'] >= 0.4)  & (melt_weight_d5x6['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_weight_d5x6['value'], lowperformance_weight_d5x6['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_weight_d5x6['value'].mean())\n",
    "print(lowperformance_weight_d5x6['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=1.25969987629252, pvalue=0.20849249939564976)\n",
      "21.716178064771334\n",
      "21.374191148646744\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_imc_d5x6 = pd.merge(imc_call_T, defense_transpose['D5x6 Overview'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_imc_d5x6 = pd.melt(merge_imc_d5x6.reset_index(),id_vars=['index','D5x6 Overview'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_imc_d5x6 = melt_imc_d5x6.loc[(melt_imc_d5x6['D5x6 Overview'] < 0.4)  & (melt_imc_d5x6['value']>0)]\n",
    "lowperformance_imc_d5x6 = melt_imc_d5x6.loc[(melt_imc_d5x6['D5x6 Overview'] >= 0.4)  & (melt_imc_d5x6['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_imc_d5x6['value'], lowperformance_imc_d5x6['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_imc_d5x6['value'].mean())\n",
    "print(lowperformance_imc_d5x6['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D6x6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.06678536252086187, pvalue=0.9467850515345964)\n",
      "180.89240506329114\n",
      "180.8403409090909\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_height_d6x6 = pd.merge(height_call_T, defense_transpose['D6x6'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_height_d6x6 = pd.melt(merge_height_d6x6.reset_index(),id_vars=['index','D6x6'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_height_d6x6 = melt_height_d6x6.loc[(melt_height_d6x6['D6x6'] < 5)  & (melt_height_d6x6['value']>0)]\n",
    "lowperformance_height_d6x6 = melt_height_d6x6.loc[(melt_height_d6x6['D6x6'] >= 5)  & (melt_height_d6x6['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_height_d6x6['value'], lowperformance_height_d6x6['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_height_d6x6['value'].mean())\n",
    "print(lowperformance_height_d6x6['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.6997822503685778, pvalue=0.48445917983451137)\n",
      "70.6658227848102\n",
      "71.19204545454548\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_weight_d6x6 = pd.merge(weight_call_T, defense_transpose['D6x6'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_weight_d6x6 = pd.melt(merge_weight_d6x6.reset_index(),id_vars=['index','D6x6'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_weight_d6x6 = melt_weight_d6x6.loc[(melt_weight_d6x6['D6x6'] < 5)  & (melt_weight_d6x6['value']>0)]\n",
    "lowperformance_weight_d6x6 = melt_weight_d6x6.loc[(melt_weight_d6x6['D6x6'] >= 5)  & (melt_weight_d6x6['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_weight_d6x6['value'], lowperformance_weight_d6x6['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_weight_d6x6['value'].mean())\n",
    "print(lowperformance_weight_d6x6['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.9423126928300581, pvalue=0.3465861185796917)\n",
      "21.592876191678922\n",
      "21.771458119906455\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_imc_d6x6 = pd.merge(imc_call_T, defense_transpose['D6x6'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_imc_d6x6 = pd.melt(merge_imc_d6x6.reset_index(),id_vars=['index','D6x6'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_imc_d6x6 = melt_imc_d6x6.loc[(melt_imc_d6x6['D6x6'] < 5)  & (melt_imc_d6x6['value']>0)]\n",
    "lowperformance_imc_d6x6 = melt_imc_d6x6.loc[(melt_imc_d6x6['D6x6'] >= 5)  & (melt_imc_d6x6['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_imc_d6x6['value'], lowperformance_imc_d6x6['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_imc_d6x6['value'].mean())\n",
    "print(lowperformance_imc_d6x6['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counter-attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.6326543786770955, pvalue=0.5273111798403203)\n",
      "180.9755747126437\n",
      "180.30615384615385\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_height_ca_d = pd.merge(height_call_T, defense_transpose['Contra-ataque'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_height_ca_d = pd.melt(merge_height_ca_d.reset_index(),id_vars=['index','Contra-ataque'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_height_ca_d = melt_height_ca_d.loc[(melt_height_ca_d['Contra-ataque'] < 3)  & (melt_height_ca_d['value']>0)]\n",
    "lowperformance_height_ca_d = melt_height_ca_d.loc[(melt_height_ca_d['Contra-ataque'] >= 3)  & (melt_height_ca_d['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_height_ca_d['value'], lowperformance_height_ca_d['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_height_ca_d['value'].mean())\n",
    "print(lowperformance_height_ca_d['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=1.2542236473838881, pvalue=0.21047357018490595)\n",
      "71.09137931034488\n",
      "69.81230769230767\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_weight_ca_d = pd.merge(weight_call_T, defense_transpose['Contra-ataque'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_weight_ca_d = pd.melt(merge_weight_ca_d.reset_index(),id_vars=['index','Contra-ataque'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_weight_ca_d = melt_weight_ca_d.loc[(melt_weight_ca_d['Contra-ataque'] < 3)  & (melt_weight_ca_d['value']>0)]\n",
    "lowperformance_weight_ca_d = melt_weight_ca_d.loc[(melt_weight_ca_d['Contra-ataque'] >= 3)  & (melt_weight_ca_d['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_weight_ca_d['value'], lowperformance_weight_ca_d['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_weight_ca_d['value'].mean())\n",
    "print(lowperformance_weight_ca_d['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.9205986284956844, pvalue=0.35780004092022755)\n",
      "21.70626797862128\n",
      "21.46933892263465\n"
     ]
    }
   ],
   "source": [
    "#merging the tables height_call_t with the scored_goals\n",
    "merge_imc_ca_d = pd.merge(imc_call_T, defense_transpose['Contra-ataque'], left_index=True, right_index=True)\n",
    "\n",
    "#melting the table created\n",
    "melt_imc_ca_d = pd.melt(merge_imc_ca_d.reset_index(),id_vars=['index','Contra-ataque'])\n",
    "\n",
    "#creating high and low performance groups\n",
    "highperformance_imc_ca_d = melt_imc_ca_d.loc[(melt_imc_ca_d['Contra-ataque'] < 3)  & (melt_imc_ca_d['value']>0)]\n",
    "lowperformance_imc_ca_d = melt_imc_ca_d.loc[(melt_imc_ca_d['Contra-ataque'] >= 3)  & (melt_imc_ca_d['value']>0)]\n",
    "\n",
    "#doing the independence test\n",
    "print(st.ttest_ind(highperformance_imc_ca_d['value'], lowperformance_imc_ca_d['value']))\n",
    "\n",
    "#just seeing the means of both low and high performance \n",
    "print(highperformance_imc_ca_d['value'].mean())\n",
    "print(lowperformance_imc_ca_d['value'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We reject the null hypothesis because in all type of goals the high performance mean and low performance mean is different. So the physical characteristics affect the type of conceded goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing our players with the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAverage height of a male olympian waterpolo player: 192.6 cm (source: https://www.topendsports.com/sport/waterpolo/anthropometry.htm)\\nAverage height of a portuguese male: 172.9 cm (source: https://www.jn.pt/infos/alturainfos/alturapessoas.html)\\n\\nAverage weight of a male olympian waterpolo player: 96.2 kg (source: https://www.topendsports.com/sport/waterpolo/anthropometry.htm)\\nAverage weight of a portuguese male: 79.8 kg (Calculated from the average height and IMC)\\n\\nAverage IMC of a male olympian waterpolo player: 25.9 (source: https://www.topendsports.com/sport/waterpolo/anthropometry.htm)\\nAverage IMC of a portuguese male: 26.7 (source: https://en.wikipedia.org/wiki/List_of_countries_by_body_mass_index)\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Average height of a male olympian waterpolo player: 192.6 cm (source: https://www.topendsports.com/sport/waterpolo/anthropometry.htm)\n",
    "Average height of a portuguese male: 172.9 cm (source: https://www.jn.pt/infos/alturainfos/alturapessoas.html)\n",
    "\n",
    "Average weight of a male olympian waterpolo player: 96.2 kg (source: https://www.topendsports.com/sport/waterpolo/anthropometry.htm)\n",
    "Average weight of a portuguese male: 79.8 kg (Calculated from the average height and IMC)\n",
    "\n",
    "Average IMC of a male olympian waterpolo player: 25.9 (source: https://www.topendsports.com/sport/waterpolo/anthropometry.htm)\n",
    "Average IMC of a portuguese male: 26.7 (source: https://en.wikipedia.org/wiki/List_of_countries_by_body_mass_index)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing with an Olympian waterpolo athlete:\n",
      "Ttest_1sampResult(statistic=-11.662410806949717, pvalue=6.6366139193551856e-15)\n",
      "Comparing with an average portuguese male:\n",
      "Ttest_1sampResult(statistic=6.515934252327425, pvalue=6.489844138712854e-08)\n"
     ]
    }
   ],
   "source": [
    "print('Comparing with an Olympian waterpolo athlete:')\n",
    "print(st.ttest_1samp(athletes['altura (cm)'], 192.6))\n",
    "print('Comparing with an average portuguese male:')\n",
    "print(st.ttest_1samp(athletes['altura (cm)'], 172.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing with an Olympian waterpolo athlete:\n",
      "Ttest_1sampResult(statistic=-20.083091903467025, pvalue=1.8013977047497024e-23)\n",
      "Comparing with an average portuguese male:\n",
      "Ttest_1sampResult(statistic=-7.037850101737075, pvalue=1.1342869651241357e-08)\n"
     ]
    }
   ],
   "source": [
    "print('Comparing with an Olympian waterpolo athlete:')\n",
    "print(st.ttest_1samp(athletes['Peso (kg)'], 96.2))\n",
    "print('Comparing with an average portuguese male:')\n",
    "print(st.ttest_1samp(athletes['Peso (kg)'], 79.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing with an Olympian waterpolo athlete:\n",
      "Ttest_1sampResult(statistic=-12.996690233156462, pvalue=1.7244264419169884e-16)\n",
      "Comparing with an average portuguese male:\n",
      "Ttest_1sampResult(statistic=-15.585015646519684, pvalue=2.676627764512672e-19)\n"
     ]
    }
   ],
   "source": [
    "print('Comparing with an Olympian waterpolo athlete:')\n",
    "print(st.ttest_1samp(athletes['IMC'], 25.9))\n",
    "print('Comparing with an average portuguese male:')\n",
    "print(st.ttest_1samp(athletes['IMC'], 26.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer the data to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing zeros with null values\n",
    "melt_height_result = melt_height_result.replace(0, np.NaN)\n",
    "melt_weight_result = melt_weight_result.replace(0, np.NaN)\n",
    "melt_imc_result = melt_imc_result.replace(0, np.NaN)\n",
    "\n",
    "\n",
    "highperformance_height_scored_goals = highperformance_height_scored_goals.replace(0, np.NaN)\n",
    "lowperformance_height_scored_goals = lowperformance_height_scored_goals.replace(0, np.NaN)\n",
    "highperformance_weight_scored_goals = highperformance_weight_scored_goals.replace(0, np.NaN)\n",
    "lowperformance_weight_scored_goals = lowperformance_weight_scored_goals.replace(0, np.NaN)\n",
    "highperformance_imc_scored_goals = highperformance_imc_scored_goals.replace(0, np.NaN)\n",
    "lowperformance_imc_scored_goals = lowperformance_imc_scored_goals.replace(0, np.NaN)\n",
    "\n",
    "highperformance_height_conceded_goals = highperformance_height_conceded_goals.replace(0, np.NaN)\n",
    "lowperformance_height_conceded_goals = lowperformance_height_conceded_goals.replace(0, np.NaN)\n",
    "highperformance_weight_conceded_goals = highperformance_weight_conceded_goals.replace(0, np.NaN)\n",
    "lowperformance_weight_conceded_goals = lowperformance_weight_conceded_goals.replace(0, np.NaN)\n",
    "highperformance_imc_conceded_goals = highperformance_imc_conceded_goals.replace(0, np.NaN)\n",
    "lowperformance_imc_conceded_goals = lowperformance_imc_conceded_goals.replace(0, np.NaN)\n",
    "\n",
    "highperformance_height_penalty = highperformance_height_penalty.replace(0, np.NaN)\n",
    "lowperformance_height_penalty = lowperformance_height_penalty.replace(0, np.NaN)\n",
    "highperformance_weight_penalty = highperformance_weight_penalty.replace(0, np.NaN)\n",
    "lowperformance_weight_penalty = lowperformance_weight_penalty.replace(0, np.NaN)\n",
    "highperformance_imc_penalty = highperformance_imc_penalty.replace(0, np.NaN)\n",
    "lowperformance_imc_penalty = lowperformance_imc_penalty.replace(0, np.NaN)\n",
    "\n",
    "\n",
    "#result\n",
    "#melt_height_result.to_excel(\"melt_height_result.xlsx\")\n",
    "#melt_weight_result.to_excel(\"melt_weight_result.xlsx\")\n",
    "#melt_imc_result.to_excel(\"melt_imc_result.xlsx\")\n",
    "\n",
    "#scored_goals\n",
    "#highperformance_height_scored_goals.to_excel('highperformance_height_scored_goals.xlsx')\n",
    "#lowperformance_height_scored_goals.to_excel('lowperformance_height_scored_goals.xlsx')\n",
    "#highperformance_weight_scored_goals.to_excel('highperformance_weight_scored_goals.xlsx')\n",
    "#lowperformance_weight_scored_goals.to_excel('lowperformance_weight_scored_goals.xlsx')\n",
    "#highperformance_imc_scored_goals.to_excel('highperformance_imc_scored_goals.xlsx')\n",
    "#lowperformance_imc_scored_goals.to_excel('lowperformance_imc_scored_goals.xlsx')\n",
    "\n",
    "#conceded_goals\n",
    "#highperformance_height_conceded_goals.to_excel('highperformance_height_conceded_goals.xlsx')\n",
    "#lowperformance_height_conceded_goals.to_excel('lowperformance_height_conceded_goals.xlsx')\n",
    "#highperformance_weight_conceded_goals.to_excel('highperformance_weight_conceded_goals.xlsx')\n",
    "#lowperformance_weight_conceded_goals.to_excel('lowperformance_weight_conceded_goals.xlsx')\n",
    "#highperformance_imc_conceded_goals.to_excel('highperformance_imc_conceded_goals.xlsx')\n",
    "#lowperformance_imc_conceded_goals.to_excel('lowperformance_imc_conceded_goals.xlsx')\n",
    "\n",
    "#penalty scored\n",
    "highperformance_height_penalty.to_excel('highperformance_height_penalty.xlsx')\n",
    "lowperformance_height_penalty.to_excel('lowperformance_height_penalty.xlsx')\n",
    "highperformance_weight_penalty.to_excel('highperformance_weight_penalty.xlsx')\n",
    "lowperformance_weight_penalty.to_excel('lowperformance_weight_penalty.xlsx')\n",
    "highperformance_imc_penalty.to_excel('highperformance_imc_penalty.xlsx')\n",
    "lowperformance_imc_penalty.to_excel('lowperformance_imc_penalty.xlsx')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
